% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_core.R
\name{Tokenizer}
\alias{Tokenizer}
\title{Tokenizer}
\usage{
Tokenizer(
  tok,
  rules = NULL,
  counter = NULL,
  lengths = NULL,
  mode = NULL,
  sep = " "
)
}
\arguments{
\item{tok}{tokenizer}

\item{rules}{rules}

\item{counter}{counter}

\item{lengths}{lengths}

\item{mode}{mode}

\item{sep}{separator}
}
\value{
None
}
\description{
Provides a consistent `Transform` interface to tokenizers operating on `DataFrame`s and folders
}
