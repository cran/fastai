% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_core.R
\name{tokenize_csv}
\alias{tokenize_csv}
\title{Tokenize_csv}
\usage{
tokenize_csv(
  fname,
  text_cols,
  outname = NULL,
  n_workers = 4,
  rules = NULL,
  mark_fields = NULL,
  tok = NULL,
  header = "infer",
  chunksize = 50000
)
}
\arguments{
\item{fname}{file name}

\item{text_cols}{text columns}

\item{outname}{outname}

\item{n_workers}{numeber of workers}

\item{rules}{rules}

\item{mark_fields}{mark fields}

\item{tok}{tokenizer}

\item{header}{header}

\item{chunksize}{chunk size}
}
\value{
None
}
\description{
Tokenize texts in the `text_cols` of the csv `fname` in parallel using `n_workers`
}
